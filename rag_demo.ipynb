{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Advanced RAG System Demo\n",
                "\n",
                "### Objectives:\n",
                "1. **System Resource Monitoring**: Track RAM/CPU usage during heavy tasks.\n",
                "2. **Pipeline Execution**: Load data, chunk, index, retrieve, and generate.\n",
                "3. **Evaluation**: Compare Generated Answers vs Reference Answers using **BLEU-4** and **ROUGE-L** metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: qdrant-client in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.16.2)\n",
                        "Requirement already satisfied: transformers in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.57.3)\n",
                        "Requirement already satisfied: sentence-transformers in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (5.2.0)\n",
                        "Requirement already satisfied: datasets in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.4.1)\n",
                        "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (2.9.1)\n",
                        "Requirement already satisfied: accelerate in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.12.0)\n",
                        "Requirement already satisfied: bitsandbytes in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.49.0)\n",
                        "Requirement already satisfied: nltk in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (3.9.2)\n",
                        "Requirement already satisfied: rouge_score in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.1.2)\n",
                        "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2.2.6)\n",
                        "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.3.3)\n",
                        "Requirement already satisfied: ipywidgets in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (8.1.8)\n",
                        "Requirement already satisfied: peft in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.18.0)\n",
                        "Requirement already satisfied: trl in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.26.1)\n",
                        "Requirement already satisfied: scipy in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (1.15.3)\n",
                        "Requirement already satisfied: wandb in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.23.1)\n",
                        "Requirement already satisfied: python-dotenv in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (1.2.1)\n",
                        "Requirement already satisfied: httpx[http2]>=0.20.0 in ./venv/lib/python3.10/site-packages (from qdrant-client->-r requirements.txt (line 1)) (0.28.1)\n",
                        "Requirement already satisfied: portalocker<4.0,>=2.7.0 in ./venv/lib/python3.10/site-packages (from qdrant-client->-r requirements.txt (line 1)) (3.2.0)\n",
                        "Requirement already satisfied: urllib3<3,>=1.26.14 in ./venv/lib/python3.10/site-packages (from qdrant-client->-r requirements.txt (line 1)) (2.6.2)\n",
                        "Requirement already satisfied: protobuf>=3.20.0 in ./venv/lib/python3.10/site-packages (from qdrant-client->-r requirements.txt (line 1)) (6.33.2)\n",
                        "Requirement already satisfied: grpcio>=1.41.0 in ./venv/lib/python3.10/site-packages (from qdrant-client->-r requirements.txt (line 1)) (1.76.0)\n",
                        "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in ./venv/lib/python3.10/site-packages (from qdrant-client->-r requirements.txt (line 1)) (2.12.5)\n",
                        "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.7.0)\n",
                        "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (6.0.3)\n",
                        "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.36.0)\n",
                        "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.22.1)\n",
                        "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (2.32.5)\n",
                        "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (3.20.0)\n",
                        "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (4.67.1)\n",
                        "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (2025.11.3)\n",
                        "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (25.0)\n",
                        "Requirement already satisfied: typing_extensions>=4.5.0 in ./venv/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 3)) (4.15.0)\n",
                        "Requirement already satisfied: scikit-learn in ./venv/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 3)) (1.7.2)\n",
                        "Requirement already satisfied: pyarrow>=21.0.0 in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 4)) (22.0.0)\n",
                        "Requirement already satisfied: multiprocess<0.70.19 in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 4)) (0.70.18)\n",
                        "Requirement already satisfied: fsspec[http]<=2025.10.0,>=2023.1.0 in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 4)) (2025.10.0)\n",
                        "Requirement already satisfied: dill<0.4.1,>=0.3.0 in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 4)) (0.4.0)\n",
                        "Requirement already satisfied: xxhash in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 4)) (3.6.0)\n",
                        "Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (1.14.0)\n",
                        "Requirement already satisfied: networkx>=2.5.1 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (3.4.2)\n",
                        "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (3.1.6)\n",
                        "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 6)) (7.1.3)\n",
                        "Requirement already satisfied: joblib in ./venv/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 8)) (1.5.2)\n",
                        "Requirement already satisfied: click in ./venv/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 8)) (8.3.1)\n",
                        "Requirement already satisfied: absl-py in ./venv/lib/python3.10/site-packages (from rouge_score->-r requirements.txt (line 9)) (2.3.1)\n",
                        "Requirement already satisfied: six>=1.14.0 in ./venv/lib/python3.10/site-packages (from rouge_score->-r requirements.txt (line 9)) (1.17.0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 11)) (2025.2)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 11)) (2025.2)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 11)) (2.9.0.post0)\n",
                        "Requirement already satisfied: comm>=0.1.3 in ./venv/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 12)) (0.2.3)\n",
                        "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./venv/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 12)) (3.0.16)\n",
                        "Requirement already satisfied: ipython>=6.1.0 in ./venv/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 12)) (8.37.0)\n",
                        "Requirement already satisfied: traitlets>=4.3.1 in ./venv/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 12)) (5.14.3)\n",
                        "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./venv/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 12)) (4.0.15)\n",
                        "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./venv/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 16)) (3.1.45)\n",
                        "Requirement already satisfied: platformdirs in ./venv/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 16)) (4.5.1)\n",
                        "Requirement already satisfied: sentry-sdk>=2.0.0 in ./venv/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 16)) (2.47.0)\n",
                        "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./venv/lib/python3.10/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (3.13.2)\n",
                        "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (6.7.0)\n",
                        "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (1.4.0)\n",
                        "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (1.22.0)\n",
                        "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (5.0.1)\n",
                        "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (1.8.0)\n",
                        "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (25.4.0)\n",
                        "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (2.6.1)\n",
                        "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (0.4.1)\n",
                        "Requirement already satisfied: gitdb<5,>=4.0.1 in ./venv/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 16)) (4.0.12)\n",
                        "Requirement already satisfied: smmap<6,>=3.0.1 in ./venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 16)) (5.0.2)\n",
                        "Requirement already satisfied: idna in ./venv/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (3.11)\n",
                        "Requirement already satisfied: anyio in ./venv/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (4.12.0)\n",
                        "Requirement already satisfied: certifi in ./venv/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (2025.11.12)\n",
                        "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (1.0.9)\n",
                        "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.10/site-packages (from httpcore==1.*->httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (0.16.0)\n",
                        "Requirement already satisfied: h2<5,>=3 in ./venv/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (4.3.0)\n",
                        "Requirement already satisfied: hyperframe<7,>=6.1 in ./venv/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (6.1.0)\n",
                        "Requirement already satisfied: hpack<5,>=4.1 in ./venv/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (4.1.0)\n",
                        "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 2)) (1.2.0)\n",
                        "Requirement already satisfied: pexpect>4.3 in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (4.9.0)\n",
                        "Requirement already satisfied: stack_data in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (0.6.3)\n",
                        "Requirement already satisfied: decorator in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (5.2.1)\n",
                        "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (3.0.52)\n",
                        "Requirement already satisfied: matplotlib-inline in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (0.2.1)\n",
                        "Requirement already satisfied: jedi>=0.16 in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (0.19.2)\n",
                        "Requirement already satisfied: pygments>=2.4.0 in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (2.19.2)\n",
                        "Requirement already satisfied: exceptiongroup in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (1.3.1)\n",
                        "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (0.8.5)\n",
                        "Requirement already satisfied: ptyprocess>=0.5 in ./venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (0.7.0)\n",
                        "Requirement already satisfied: wcwidth in ./venv/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (0.2.14)\n",
                        "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client->-r requirements.txt (line 1)) (2.41.5)\n",
                        "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client->-r requirements.txt (line 1)) (0.7.0)\n",
                        "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client->-r requirements.txt (line 1)) (0.4.2)\n",
                        "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 2)) (3.4.4)\n",
                        "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 5)) (1.3.0)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 5)) (3.0.3)\n",
                        "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 3)) (3.6.0)\n",
                        "Requirement already satisfied: pure-eval in ./venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (0.2.3)\n",
                        "Requirement already satisfied: executing>=1.2.0 in ./venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (2.2.1)\n",
                        "Requirement already satisfied: asttokens>=2.1.0 in ./venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (3.0.1)\n",
                        "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
                        "You should consider upgrading via the '/Users/gizemcidal/Desktop/rag_and_finetuning_task_vdf/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "# Setup Environment & Utils\n",
                "!pip install -r requirements.txt\n",
                "\n",
                "import sys\n",
                "import os\n",
                "import psutil\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Ensure src is in python path\n",
                "sys.path.append(os.getcwd())\n",
                "\n",
                "def print_system_usage(stage=\"\"):\n",
                "    process = psutil.Process(os.getpid())\n",
                "    mem_info = process.memory_info()\n",
                "    mem_mb = mem_info.rss / 1024 / 1024\n",
                "    print(f\"[{stage}] Memory: {mem_mb:.2f} MB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Configuration Loaded.\n",
                        "[Init] Memory: 521.23 MB\n"
                    ]
                }
            ],
            "source": [
                "# Load Configuration & Modules\n",
                "from rag.config import RAGConfig\n",
                "from rag.data_loader import DataLoader\n",
                "from rag.chunking import HierarchicalChunker\n",
                "from rag.vector_db import VectorDBHandler\n",
                "from rag.retriever import HierarchicalRetriever\n",
                "from rag.generator import RAGGenerator\n",
                "from rag.evaluator import Evaluator\n",
                "\n",
                "config = RAGConfig()\n",
                "print(\"Configuration Loaded.\")\n",
                "print_system_usage(\"Init\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Logging in with token from .env...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
                    ]
                }
            ],
            "source": [
                "# Authenticate with Hugging Face (Required for Gemma Model)\n",
                "from huggingface_hub import login\n",
                "\n",
                "# Load existing .env file\n",
                "load_dotenv()\n",
                "hf_token = os.getenv(\"HF_TOKEN\")\n",
                "\n",
                "if hf_token and hf_token != \"your_huggingface_token_here\":\n",
                "    print(\"Logging in with token from .env...\")\n",
                "    login(token=hf_token)\n",
                "else:\n",
                "    print(\"Please Paste Token manually or update .env file.\")\n",
                "    print(\"Get token: https://huggingface.co/settings/tokens\")\n",
                "    login()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`trust_remote_code` is not supported anymore.\n",
                        "Please check that the Hugging Face dataset 'narrativeqa' isn't based on a loading script and remove `trust_remote_code`.\n",
                        "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Book already exists at /Users/gizemcidal/Desktop/rag_and_finetuning_task_vdf/data/zuleika_dobson.txt\n",
                        "Book loaded. Length: 467598 chars\n",
                        "Loading NarrativeQA test split for ID 1845...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "41d27e4486334b44bc7684ee3ee9a61c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Resolving data files:   0%|          | 0/24 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1167b49779154584ab71755c8ca740af",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Resolving data files:   0%|          | 0/24 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 40 QA pairs for Book ID 1845.\n",
                        "Loaded 40 QA pairs for testing.\n",
                        "[Data Loading] Memory: 572.02 MB\n"
                    ]
                }
            ],
            "source": [
                "# Data Loading\n",
                "loader = DataLoader(config)\n",
                "\n",
                "# Download Book\n",
                "book_text = loader.download_book()\n",
                "print(f\"Book loaded. Length: {len(book_text)} chars\")\n",
                "\n",
                "# Load QA Pairs\n",
                "qa_pairs = loader.load_qa_pairs()\n",
                "print(f\"Loaded {len(qa_pairs)} QA pairs for testing.\")\n",
                "print_system_usage(\"Data Loading\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- DIAGNOSTICS: Text Hygiene Check ---\n",
                        "\n",
                        "[Hard Wraps] Potential artificial line breaks mid-sentence: 4942\n",
                        "Examples (WordEnd - Newline - WordStart):\n",
                        "  '...with[\\n]almost no restrictions wh...'\n",
                        "  '...or[\\n]re-use it under the terms o...'\n",
                        "  '...included[\\n]with this eBook or on...'\n",
                        "\n",
                        "[Whitespace] Sequences of multiple spaces found: 156\n",
                        "  Example: '...hatsoever.  You may co...'\n",
                        "\n",
                        "[Hyphenation] Words split by hyphen+newline: 0\n"
                    ]
                }
            ],
            "source": [
                "# Visualize 'Dirty' Patterns: Hard Wraps, Extra Spaces, Hyphenation\n",
                "import re\n",
                "\n",
                "print(\"--- DIAGNOSTICS: Text Hygiene Check ---\")\n",
                "\n",
                "# 1. Hard Wraps (Lines split by single \\n)\n",
                "# Finding snippets where a line break occurs mid-sentence (surrounded by lowercase/words)\n",
                "hard_wrap_pattern = r'([a-z,]+)\\n([a-z]+)'\n",
                "matches_hw = re.findall(hard_wrap_pattern, book_text)\n",
                "print(f\"\\n[Hard Wraps] Potential artificial line breaks mid-sentence: {len(matches_hw)}\")\n",
                "if matches_hw:\n",
                "    print(\"Examples (WordEnd - Newline - WordStart):\")\n",
                "    # Let's verify by checking contexts in the actual text\n",
                "    # Displaying a few snippets\n",
                "    snippet_indices = [m.start() for m in re.finditer(hard_wrap_pattern, book_text)][:3]\n",
                "    for idx in snippet_indices:\n",
                "        safe_snippet = book_text[idx:idx+30].replace(chr(10), '[\\\\n]')\n",
                "        print(f\"  '...{safe_snippet}...'\")\n",
                "\n",
                "# 2. Excessive Whitespace\n",
                "matches_ws = re.findall(r'[ ]{2,}', book_text)\n",
                "print(f\"\\n[Whitespace] Sequences of multiple spaces found: {len(matches_ws)}\")\n",
                "if matches_ws:\n",
                "    # Find a context example\n",
                "    ws_obj = re.search(r'[ ]{2,}', book_text)\n",
                "    if ws_obj:\n",
                "        start = max(0, ws_obj.start() - 10)\n",
                "        end = min(len(book_text), ws_obj.end() + 10)\n",
                "        print(f\"  Example: '...{book_text[start:end]}...'\")\n",
                "\n",
                "# 3. Hyphenation at Line End\n",
                "matches_hyphen = re.findall(r'(\\w+-\\n\\w+)', book_text)\n",
                "print(f\"\\n[Hyphenation] Words split by hyphen+newline: {len(matches_hyphen)}\")\n",
                "if matches_hyphen:\n",
                "    print(\"Examples:\", matches_hyphen[:3])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total Character Count: 467598\n",
                        "--- First 500 Characters (Should be CLEAN text, no Gutenberg headers) ---\n",
                        "The Project Gutenberg EBook of Zuleika Dobson, by Max Beerbohm\n",
                        "\n",
                        "This eBook is for the use of anyone anywhere at no cost and with\n",
                        "almost no restrictions whatsoever.  You may copy it, give it away or\n",
                        "re-use it under the terms of the Project Gutenberg License included\n",
                        "with this eBook or online at www.gutenberg.org\n",
                        "\n",
                        "\n",
                        "Title: Zuleika Dobson\n",
                        "       or, An Oxford Love Story\n",
                        "\n",
                        "Author: Max Beerbohm\n",
                        "\n",
                        "Posting Date: November 25, 2008 [EBook #1845]\n",
                        "Release Date: August, 1999\n",
                        "Last Updated: October 18, 2016\n",
                        "\n",
                        "Language: English\n",
                        "\n",
                        "Character set encoding: UTF-8\n",
                        "\n",
                        "*** START OF THIS PROJECT GUTENBERG EBOOK ZULEIKA DOBSON ***\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "Produced by Judy Boss\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "ZULEIKA DOBSON\n",
                        "\n",
                        "or, AN OXFORD LOVE STORY\n",
                        "\n",
                        "By Max Beerbohm\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "         NOTE to the 1922 edition\n",
                        "\n",
                        "         I was in Italy when this book was first published.\n",
                        "         A year later (1912) I visited London, and I found\n",
                        "         that most of my friends and acquaintances spoke to\n",
                        "         me of Zu-like-a--a name which I hardly recognised\n",
                        "         and thoroughly disapproved. I had always thought\n",
                        "         of the lady as Zu-leek-a. Surely it was thus that\n",
                        "         Joseph thought of his Wife, and Selim of his Bride?\n",
                        "         And I do hope that it is thus that any reader of\n",
                        "         these pages will think of Miss Dobson.\n",
                        "\n",
                        "                                              M.B.\n",
                        "                                              Rapallo, 1922.\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "ILLI ALMAE MATRI\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "ZULEIKA DOBSON\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "I\n",
                        "\n",
                        "That old bell, presage of a train, had just sounded through Oxford\n",
                        "station; and the undergraduates who were waiting there, gay figures in\n",
                        "tweed or flannel, moved to the margin of the platform and gazed idly\n",
                        "up the line. Young and careless, in the glow of the afternoon sunshine,\n",
                        "they struck a sharp note of incongruity with the worn boards they stood\n",
                        "on, with the fading signals and grey eternal walls of that antique\n",
                        "station, which, familiar to them and insignificant, does yet whisper to\n",
                        "the tourist the last enchantments of the Middle Age.\n",
                        "\n",
                        "At the door of the first-class waiting-room, aloof and venerable, stood\n",
                        "the Warden of Judas. An ebon pillar of tradition seemed he, in his garb\n",
                        "of old-fashioned cleric. Aloft, between the wide brim of his silk hat\n",
                        "and the white extent of his shirt-front, appeared those eyes which\n",
                        "hawks, that nose which eagles, had often envied. He supported his years\n",
                        "on an ebon stick. He alone was worthy of the background.\n",
                        "\n",
                        "Came a whistle from the distance. The breast of an engine was descried,\n",
                        "and a long train curving after it, under a flight of \n",
                        "\n",
                        "--- Last 500 Characters (Should be CLEAN text, no legalese) ---\n",
                        "it takes a\n",
                        "considerable effort, much paperwork and many fees to meet and keep up\n",
                        "with these requirements.  We do not solicit donations in locations\n",
                        "where we have not received written confirmation of compliance.  To\n",
                        "SEND DONATIONS or determine the status of compliance for any\n",
                        "particular state visit http://pglaf.org\n",
                        "\n",
                        "While we cannot and do not solicit contributions from states where we\n",
                        "have not met the solicitation requirements, we know of no prohibition\n",
                        "against accepting unsolicited donations from donors in such states who\n",
                        "approach us with offers to donate.\n",
                        "\n",
                        "International donations are gratefully accepted, but we cannot make\n",
                        "any statements concerning tax treatment of donations received from\n",
                        "outside the United States.  U.S. laws alone swamp our small staff.\n",
                        "\n",
                        "Please check the Project Gutenberg Web pages for current donation\n",
                        "methods and addresses.  Donations are accepted in a number of other\n",
                        "ways including checks, online payments and credit card donations.\n",
                        "To donate, please visit: http://pglaf.org/donate\n",
                        "\n",
                        "\n",
                        "Section 5.  General Information About Project Gutenberg-tm electronic\n",
                        "works.\n",
                        "\n",
                        "Professor Michael S. Hart is the originator of the Project Gutenberg-tm\n",
                        "concept of a library of electronic works that could be freely shared\n",
                        "with anyone.  For thirty years, he produced and distributed Project\n",
                        "Gutenberg-tm eBooks with only a loose network of volunteer support.\n",
                        "\n",
                        "\n",
                        "Project Gutenberg-tm eBooks are often created from several printed\n",
                        "editions, all of which are confirmed as Public Domain in the U.S.\n",
                        "unless a copyright notice is included.  Thus, we do not necessarily\n",
                        "keep eBooks in compliance with any particular paper edition.\n",
                        "\n",
                        "\n",
                        "Most people start at our Web site which has the main PG search facility:\n",
                        "\n",
                        "     http://www.gutenberg.org\n",
                        "\n",
                        "This Web site includes information about Project Gutenberg-tm,\n",
                        "including how to make donations to the Project Gutenberg Literary\n",
                        "Archive Foundation, how to help produce our new eBooks, and how to\n",
                        "subscribe to our email newsletter to hear about new eBooks.\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Total Character Count: {len(book_text)}\")\n",
                "print(\"--- First 500 Characters (Should be CLEAN text, no Gutenberg headers) ---\")\n",
                "print(book_text[:2500])\n",
                "print(\"\\n--- Last 500 Characters (Should be CLEAN text, no legalese) ---\")\n",
                "print(book_text[-2000:])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total QA Pairs available for testing: 40\n",
                        "--- Random Sample of 3 Questions ---\n",
                        "Q1: Where does Zulika go when she leaves Oxford?\n",
                        "A1: Cambridge.\n",
                        "------------------------------\n",
                        "Q2: Who does Zuleika fall in with love while at school?\n",
                        "A2: The Duke of Dorset.\n",
                        "------------------------------\n",
                        "Q3: Who is the first person Zuleika falls in love with?\n",
                        "A3: The Duke of Dorset\n",
                        "------------------------------\n"
                    ]
                }
            ],
            "source": [
                "import random\n",
                "print(f\"Total QA Pairs available for testing: {len(qa_pairs)}\")\n",
                "print(\"--- Random Sample of 3 Questions ---\")\n",
                "for i, item in enumerate(random.sample(qa_pairs, 3)):\n",
                "    print(f\"Q{i+1}: {item['question']}\")\n",
                "    print(f\"A{i+1}: {item['answer1']}\")\n",
                "    print(\"-\" * 30)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Created 346 parent chunks and 30866 child chunks.\n",
                        "[Chunking] Memory: 580.94 MB\n"
                    ]
                }
            ],
            "source": [
                "# Hierarchical Chunking\n",
                "chunker = HierarchicalChunker(\n",
                "    parent_chunk_size=config.PARENT_CHUNK_SIZE,\n",
                "    child_chunk_size=config.CHILD_CHUNK_SIZE,\n",
                "    overlap=config.CHUNK_OVERLAP\n",
                ")\n",
                "\n",
                "chunks = chunker.chunk_data(book_text)\n",
                "print(f\"Created {len(chunks['parents'])} parent chunks and {len(chunks['children'])} child chunks.\")\n",
                "\n",
                "parents = chunks['parents']\n",
                "children = chunks['children']\n",
                "print_system_usage(\"Chunking\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "*** PARENT CHUNK (ID: acb8ef14-b8bd-4eb4-938d-15c5361fbe13) ***\n",
                        "Length: 1998 chars\n",
                        "Content: single process. She was one of those who are born to make chaos cosmic.\n",
                        "\n",
                        "Insomuch that ere the loud chapel-clock tolled another hour all the\n",
                        "trunks had been sent empty away. The carpet was unflecked by any scrap\n",
                        "of silver-paper. From the mantelpiece, photographs of Zuleika surveyed\n",
                        "the room with a p... [truncated]\n",
                        "\n",
                        "    || Converted into CHILDREN ||\n",
                        "    \\/\n",
                        "    > Child 1 (ID: 543d7785-14b9-499b-8b35-96f48be44e2a): single process. She was one of those who are born to make chaos cosmic.\n",
                        "\n",
                        "Insomuch that ere the loud ... (Len: 497)\n",
                        "    > Child 2 (ID: 3ed86c8a-e3cf-44a4-b913-66ac556df3f8): able, and round it stood\n",
                        "a multitude of multiform glass vessels, domed, all of them, with dull\n",
                        "gold,... (Len: 495)\n",
                        "    > Child 3 (ID: fd3ef0e1-5f07-43da-b657-f7160ff011ca): ack of the other, A.B.C. GUIDE, in amethysts,\n",
                        "beryls, chrysoprases, and garnets. And Zuleikaâ€™s great... (Len: 493)\n",
                        "    > Child 4 (ID: a02991d7-94ee-4739-bca4-81cb85e0b4be): he Warden, with hospitable words, left his\n",
                        "grand-daughter at the threshold.\n",
                        "\n",
                        "Zuleika wandered to her... (Len: 492)\n",
                        "    > Child 5 (ID: 7704cfc2-723d-4df9-af42-f68ab2b5293b): ow. The quadrangle below was very beautiful, with its walls of\n",
                        "rugged grey, its cloisters, its grass... (Len: 421)\n",
                        "    > Child 6 (ID: 6bebec4e-099d-47bd-ab77-1cefdb426191): ething she desired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 100)\n",
                        "    > Child 7 (ID: cfcb67ee-3f37-47fd-887c-9a069fcb8046): thing she desired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 99)\n",
                        "    > Child 8 (ID: 5c5194e6-2fb2-4aeb-84a1-34857c0335bf): hing she desired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 98)\n",
                        "    > Child 9 (ID: fa4d738b-6a92-493d-bef5-6fcc82a46d97): ing she desired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 97)\n",
                        "    > Child 10 (ID: f47ce5db-49fa-46a4-bb23-d11b7cdcb086): ng she desired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 96)\n",
                        "    > Child 11 (ID: 09e4f321-f355-4f45-86b6-fd708aa2a3bc): g she desired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 95)\n",
                        "    > Child 12 (ID: 95db8057-d218-4004-81cf-8e1848733479): she desired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 93)\n",
                        "    > Child 13 (ID: a5913e6b-6e5d-4bbd-bc90-568b36a001cb): she desired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 93)\n",
                        "    > Child 14 (ID: dc06d925-d979-48f2-89ad-11f4d29e6383): he desired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 92)\n",
                        "    > Child 15 (ID: e2f82d84-7bd5-41b7-b4af-6f81057d1a04): e desired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 91)\n",
                        "    > Child 16 (ID: f0aa98a6-121f-40b6-ab80-a1d8b206aec9): desired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 89)\n",
                        "    > Child 17 (ID: 4d6515df-26d0-480f-9b2d-e67fd4dfa086): desired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 89)\n",
                        "    > Child 18 (ID: adb67938-f8d8-4f35-84ab-048ee5800f0a): esired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 88)\n",
                        "    > Child 19 (ID: 87e13665-cc1d-4a1b-9ced-7ee29899095e): sired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 87)\n",
                        "    > Child 20 (ID: 6702c263-f5fb-4df9-8705-2372cef0bc9a): ired, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 86)\n",
                        "    > Child 21 (ID: 11a31809-8096-4c81-96ac-03d80da841b5): red, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 85)\n",
                        "    > Child 22 (ID: 747e9909-6a7b-4c7a-b491-90adf3a3d667): ed, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 84)\n",
                        "    > Child 23 (ID: 438637c5-1309-4aad-a74e-dfe9cc93a4b3): d, or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 83)\n",
                        "    > Child 24 (ID: f5723e68-58da-4ea9-9ce6-ef561e6b3130): , or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 82)\n",
                        "    > Child 25 (ID: 9296dbd1-3406-4cfe-9fd0-f4147e4bb9f2): or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 80)\n",
                        "    > Child 26 (ID: ea01dc06-cc63-4903-9fb4-abbd510b0318): or of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 80)\n",
                        "    > Child 27 (ID: 5d2b7d43-30e0-4acc-a5cf-044884033bdf): r of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 79)\n",
                        "    > Child 28 (ID: 41723b4e-0d91-4dd9-a776-67d09719e98d): of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 77)\n",
                        "    > Child 29 (ID: aa35d161-6423-4746-a36a-2dc38c283078): of\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 77)\n",
                        "    > Child 30 (ID: af31394b-d9f9-4bd3-8eb0-963752c053ea): f\n",
                        "some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 76)\n",
                        "    > Child 31 (ID: d40351ed-b7cd-4118-bac0-501cebcd80a5): some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 74)\n",
                        "    > Child 32 (ID: d2f741a1-a248-447f-a43e-e85fe57cfb54): some one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 74)\n",
                        "    > Child 33 (ID: c01bdbcc-92fa-4ce0-808b-1996bebe286b): ome one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 73)\n",
                        "    > Child 34 (ID: 74ad2522-9d65-4136-a874-a0767b2e3e18): me one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 72)\n",
                        "    > Child 35 (ID: 880a9078-1996-4ae8-a580-bd9d9c2ff43f): e one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 71)\n",
                        "    > Child 36 (ID: 28843173-bfca-4498-82e2-1afa40fc081e): one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 69)\n",
                        "    > Child 37 (ID: 9f8d25d0-367e-4d17-aef7-46fa98bd3373): one she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 69)\n",
                        "    > Child 38 (ID: 57cd47bb-09c9-4f4f-8649-87b4157ed9a9): ne she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 68)\n",
                        "    > Child 39 (ID: cede9a9d-cf1b-4128-9109-fc75afd8b4de): e she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 67)\n",
                        "    > Child 40 (ID: 32a429ca-64bd-4033-8623-65dd1e5b8fa2): she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 65)\n",
                        "    > Child 41 (ID: 933685fa-bbbb-4c3f-bdc6-c9377c2f373e): she had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 65)\n",
                        "    > Child 42 (ID: 6c1cee12-fec9-489d-b033-537ee99c826e): he had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 64)\n",
                        "    > Child 43 (ID: e2ab0d59-fc34-45c5-a945-1d5c0d61aa2b): e had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 63)\n",
                        "    > Child 44 (ID: c33b25fb-8b58-4562-b55d-64004778e971): had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 61)\n",
                        "    > Child 45 (ID: 3dc51f75-0a2b-4a3a-a22a-0e6b9d57f67f): had never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 61)\n",
                        "    > Child 46 (ID: f46bf6a3-af7e-4ad5-b82b-b9f24e69e285): ad never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 60)\n",
                        "    > Child 47 (ID: c4f9ab1d-f21d-4975-8392-a5f89487ee20): d never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 59)\n",
                        "    > Child 48 (ID: 5f2a7d43-3ffb-45d0-969a-06532bd4196c): never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 57)\n",
                        "    > Child 49 (ID: a705f15c-82ba-4f2f-80fa-af06256a3c53): never met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 57)\n",
                        "    > Child 50 (ID: 52727416-9564-410e-b077-00c5bdd47282): ever met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 56)\n",
                        "    > Child 51 (ID: b5f4e1d8-7540-4da3-882b-76c6a8a4dbe9): ver met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 55)\n",
                        "    > Child 52 (ID: b7c46e20-14a3-4325-8125-5ca9445e18fc): er met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 54)\n",
                        "    > Child 53 (ID: c0a0a4cb-9df4-480a-acd6-0975be9f5e8f): r met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 53)\n",
                        "    > Child 54 (ID: 6fe3449e-40b1-4e1d-9bdc-e64e4ae6a718): met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 51)\n",
                        "    > Child 55 (ID: fddfb507-85f3-48a3-8d71-6c6e4152621d): met. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 51)\n",
                        "    > Child 56 (ID: 1b6f4370-99c2-412f-8079-ad3ec3fb3f24): et. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 50)\n",
                        "    > Child 57 (ID: d866e18a-8fd0-4d15-a350-c4f63a5a2ef6): t. There was ennui, and there was wistfulness,\n",
                        "in... (Len: 49)\n",
                        "    > Child 58 (ID: d3780026-f1c2-4d37-8d0a-d31c83ab3385): . There was ennui, and there was wistfulness,\n",
                        "in... (Len: 48)\n",
                        "    > Child 59 (ID: 1af89443-2bee-484d-ae22-42e91a343486): There was ennui, and there was wistfulness,\n",
                        "in... (Len: 46)\n",
                        "    > Child 60 (ID: 62f5260c-0856-4f95-9b9f-359ae8e35645): There was ennui, and there was wistfulness,\n",
                        "in... (Len: 46)\n",
                        "    > Child 61 (ID: 43f8ecd3-12b4-45e8-a6f9-e812b8c05922): here was ennui, and there was wistfulness,\n",
                        "in... (Len: 45)\n",
                        "    > Child 62 (ID: 5a3876a0-90ea-41de-b137-f9924dc5a0a8): ere was ennui, and there was wistfulness,\n",
                        "in... (Len: 44)\n",
                        "    > Child 63 (ID: a006a792-d786-48e0-bad7-65143fb8fc04): re was ennui, and there was wistfulness,\n",
                        "in... (Len: 43)\n",
                        "    > Child 64 (ID: d461a4ed-59fa-4146-8bef-a2e81311c08a): e was ennui, and there was wistfulness,\n",
                        "in... (Len: 42)\n",
                        "    > Child 65 (ID: 62c930dd-4755-426d-b7c1-562734a2143b): was ennui, and there was wistfulness,\n",
                        "in... (Len: 40)\n",
                        "    > Child 66 (ID: f1d766fd-df59-4475-827f-e861ee73fcb5): was ennui, and there was wistfulness,\n",
                        "in... (Len: 40)\n",
                        "    > Child 67 (ID: 5bc5c4b6-0448-41e2-9dde-ee5a6215cc15): as ennui, and there was wistfulness,\n",
                        "in... (Len: 39)\n",
                        "    > Child 68 (ID: 79d14035-184b-4368-a068-52f26d9d24ac): s ennui, and there was wistfulness,\n",
                        "in... (Len: 38)\n",
                        "    > Child 69 (ID: 9a0d099f-f195-4763-97e0-fa97326321f8): ennui, and there was wistfulness,\n",
                        "in... (Len: 36)\n",
                        "    > Child 70 (ID: 64201ba5-9b54-4a4b-ba4e-9eed428979d3): ennui, and there was wistfulness,\n",
                        "in... (Len: 36)\n",
                        "    > Child 71 (ID: ddea5417-e861-4429-8940-f989443fc304): nnui, and there was wistfulness,\n",
                        "in... (Len: 35)\n",
                        "    > Child 72 (ID: 2ef6197d-ed43-4ade-9030-2e11e332ed58): nui, and there was wistfulness,\n",
                        "in... (Len: 34)\n",
                        "    > Child 73 (ID: 8fe702b4-a91f-40f7-8c8c-b4bc4e26bbcf): ui, and there was wistfulness,\n",
                        "in... (Len: 33)\n",
                        "    > Child 74 (ID: 76d85e9f-678c-4443-b8c5-a91a56b38b78): i, and there was wistfulness,\n",
                        "in... (Len: 32)\n",
                        "    > Child 75 (ID: 768e10b7-fb21-4ec7-a781-4209e2e4e775): , and there was wistfulness,\n",
                        "in... (Len: 31)\n",
                        "    > Child 76 (ID: 975663e2-b960-4dc3-b0d2-4846da43be71): and there was wistfulness,\n",
                        "in... (Len: 29)\n",
                        "    > Child 77 (ID: 40e52f56-4b08-4506-8bed-b9fa3f518b6b): and there was wistfulness,\n",
                        "in... (Len: 29)\n",
                        "    > Child 78 (ID: c91d56b7-4c9c-491b-b2cb-b21a2841f647): nd there was wistfulness,\n",
                        "in... (Len: 28)\n",
                        "    > Child 79 (ID: 752f26b9-e3cb-4df4-9419-86032af2de9a): d there was wistfulness,\n",
                        "in... (Len: 27)\n",
                        "    > Child 80 (ID: f1f1e733-bfde-4eff-b5bd-41378d919331): there was wistfulness,\n",
                        "in... (Len: 25)\n",
                        "    > Child 81 (ID: f74020a9-ac6c-4966-b71f-b0897a792d04): there was wistfulness,\n",
                        "in... (Len: 25)\n",
                        "    > Child 82 (ID: ddc819d0-d05e-4253-ad38-b6c502f6e423): here was wistfulness,\n",
                        "in... (Len: 24)\n",
                        "    > Child 83 (ID: e30ad6e2-ee60-4ad9-b625-cf1abce2d979): ere was wistfulness,\n",
                        "in... (Len: 23)\n",
                        "    > Child 84 (ID: 98e1ed3a-3a36-4410-9956-244b0f8fcf80): re was wistfulness,\n",
                        "in... (Len: 22)\n",
                        "    > Child 85 (ID: 5418f042-17ad-42fc-a6f2-503e3e6c8f11): e was wistfulness,\n",
                        "in... (Len: 21)\n",
                        "    > Child 86 (ID: 1fca8d32-10fb-42d0-bf6a-7a1e5485892f): was wistfulness,\n",
                        "in... (Len: 19)\n",
                        "    > Child 87 (ID: 39ffd881-d634-44e1-ad9c-3a3ffbb678fe): was wistfulness,\n",
                        "in... (Len: 19)\n",
                        "    > Child 88 (ID: 746d1e90-515b-4f2e-8c05-4ca4b1ed48c5): as wistfulness,\n",
                        "in... (Len: 18)\n",
                        "    > Child 89 (ID: 7f71bafe-3244-4c06-93bf-2a360f5261a7): s wistfulness,\n",
                        "in... (Len: 17)\n",
                        "    > Child 90 (ID: 1b0e0f7e-4fee-4834-aeb3-837278e771b2): wistfulness,\n",
                        "in... (Len: 15)\n",
                        "    > Child 91 (ID: 16cd42eb-b839-4117-9c21-4f9c7c1d29a7): wistfulness,\n",
                        "in... (Len: 15)\n",
                        "    > Child 92 (ID: 59ba34ac-77ee-4a7c-bc66-6f58936ca298): istfulness,\n",
                        "in... (Len: 14)\n",
                        "    > Child 93 (ID: 2896a778-dace-4346-90e4-a3c9eae5c794): stfulness,\n",
                        "in... (Len: 13)\n",
                        "    > Child 94 (ID: 78ac1d8a-cd46-4df8-9907-f315b0ec7e1c): tfulness,\n",
                        "in... (Len: 12)\n",
                        "    > Child 95 (ID: 5c64085e-84bb-480b-aadf-b64e4177d919): fulness,\n",
                        "in... (Len: 11)\n",
                        "    > Child 96 (ID: ffe9852c-1542-4ea7-83fd-f4b8821d4fdd): ulness,\n",
                        "in... (Len: 10)\n",
                        "    > Child 97 (ID: 4f23cc52-8ec3-4db7-ade7-47e670409524): lness,\n",
                        "in... (Len: 9)\n",
                        "    > Child 98 (ID: bb28e788-bff7-4e5b-af3d-c04d58186a1b): ness,\n",
                        "in... (Len: 8)\n",
                        "    > Child 99 (ID: 6b2336ca-2993-4f04-a23a-05bd65b5448c): ess,\n",
                        "in... (Len: 7)\n",
                        "    > Child 100 (ID: 50afc90b-9ea5-4cde-89c0-b999ac091f60): ss,\n",
                        "in... (Len: 6)\n",
                        "    > Child 101 (ID: 78438871-ed31-451b-9b7b-2b53db3ca73b): s,\n",
                        "in... (Len: 5)\n",
                        "    > Child 102 (ID: c9c4e1d0-e09c-404f-bef9-d4b174dabdf5): ,\n",
                        "in... (Len: 4)\n",
                        "    > Child 103 (ID: 95548cb0-d83b-4476-8504-2b5e5c33eb99): in... (Len: 2)\n",
                        "    > Child 104 (ID: 09245526-61d3-4faa-8597-4c5a43252df1): in... (Len: 2)\n",
                        "    > Child 105 (ID: 43a2bb6a-b40d-4d30-9970-a632dc7796ab): n... (Len: 1)\n"
                    ]
                }
            ],
            "source": [
                "parent_ids = list(parents.keys())\n",
                "example_parent_id = parent_ids[5]\n",
                "parent_text = parents[example_parent_id]\n",
                "\n",
                "print(f\"*** PARENT CHUNK (ID: {example_parent_id}) ***\")\n",
                "print(f\"Length: {len(parent_text)} chars\")\n",
                "print(f\"Content: {parent_text[:300]}... [truncated]\")\n",
                "\n",
                "print(\"\\n    || Converted into CHILDREN ||\")\n",
                "print(\"    \\/\")\n",
                "\n",
                "related_children = [c for c in children if c['parent_id'] == example_parent_id]\n",
                "for i, child in enumerate(related_children):\n",
                "    print(f\"    > Child {i+1} (ID: {child['child_id']}): {child['text'][:100]}... (Len: {len(child['text'])})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Initializing Qdrant at /Users/gizemcidal/Desktop/rag_and_finetuning_task_vdf/data/qdrant_db\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/gizemcidal/Desktop/rag_and_finetuning_task_vdf/rag/vector_db.py:13: UserWarning: Local mode is not recommended for collections with more than 20,000 points. Collection <gutenberg_1845_children> contains 30866 points. Consider using Qdrant in Docker or Qdrant Cloud for better performance with large datasets.\n",
                        "  self.client = QdrantClient(path=self.config.QDRANT_PATH)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collection gutenberg_1845_children already exists.\n",
                        "Indexing chunks... (this creates embeddings using CPU/GPU)\n",
                        "Generating embeddings for 30866 chunks...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c45fef72cc3b49858b56f996d5c2351a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Batches:   0%|          | 0/965 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/gizemcidal/Desktop/rag_and_finetuning_task_vdf/rag/vector_db.py:52: UserWarning: Local mode is not recommended for collections with more than 20,000 points. Current collection contains 30966 points. Consider using Qdrant in Docker or Qdrant Cloud for better performance with large datasets.\n",
                        "  self.client.upsert(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Upserted 30866 points.\n",
                        "[Indexing] Memory: 2011.97 MB\n"
                    ]
                }
            ],
            "source": [
                "import gc\n",
                "try:\n",
                "    if 'vdb' in locals():\n",
                "        print(\"Cleaning up previous DB instance...\")\n",
                "        if hasattr(vdb, 'close'):\n",
                "            vdb.close()\n",
                "        del vdb\n",
                "        gc.collect() \n",
                "except Exception as e:\n",
                "    print(f\"Cleanup warning: {e}\")\n",
                "\n",
                "vdb = VectorDBHandler(config)\n",
                "\n",
                "\n",
                "from sentence_transformers import SentenceTransformer\n",
                "embedding_model = SentenceTransformer(config.EMBEDDING_MODEL_NAME)\n",
                "vdb.create_collection()\n",
                "\n",
                "print(\"Indexing chunks... (this creates embeddings using CPU/GPU)\")\n",
                "vdb.index_chunks(chunks, embedding_model)\n",
                "print_system_usage(\"Indexing\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
                        "Loading Reranker model: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f20700f22fd84bef9462b0f9efa8f53e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6f4eb88a0e2d4996b17eb397d9d2677a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "47a9b0e0fc6044e393caba9a10965d30",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer_config.json: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "62de2f1c612846658866ab809a208b5b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "vocab.txt: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4fb99782b65146128f816c2cecb11b74",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer.json: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3d9bfb66630b4085b0ca52db4e6aadcd",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "737d19347da7403e8653dffc75efd59a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "README.md: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading LLM: google/gemma-3-1b-it\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`torch_dtype` is deprecated! Use `dtype` instead!\n",
                        "Device set to use mps\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "RAG Components Ready.\n",
                        "[Model Load] Memory: 1234.86 MB\n"
                    ]
                }
            ],
            "source": [
                "# Initialize Components\n",
                "retriever = HierarchicalRetriever(config, vdb, parents, embedding_model)\n",
                "generator = RAGGenerator(config)\n",
                "evaluator = Evaluator()\n",
                "print(\"RAG Components Ready.\")\n",
                "print_system_usage(\"Model Load\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Running RAG on 5 queries...\n",
                        ".....\n",
                        "Done!\n",
                        "[Inference Complete] Memory: 3512.67 MB\n"
                    ]
                }
            ],
            "source": [
                "# Run RAG Loop & Evaluation\n",
                "import pandas as pd\n",
                "\n",
                "# Run on a subset or all pairs\n",
                "test_pairs = qa_pairs[:5] # Testing on first 5 pairs for demo speed\n",
                "results = []\n",
                "\n",
                "print(f\"Running RAG on {len(test_pairs)} queries...\")\n",
                "\n",
                "for i, qa in enumerate(test_pairs):\n",
                "    question = qa['question']\n",
                "    reference = qa['answer1']\n",
                "    \n",
                "    # 1. Retrieve\n",
                "    context = retriever.retrieve_context(question, top_k=config.TOP_K)\n",
                "    \n",
                "    # 2. Generate\n",
                "    generated_answer = generated_answer = generator.generate_answer(question, context, do_sample=False)\n",
                "    \n",
                "    # 3. Evaluate\n",
                "    scores = evaluator.evaluate(generated_answer, reference)\n",
                "    \n",
                "    results.append({\n",
                "        \"Question\": question,\n",
                "        \"Generated Answer\": generated_answer,\n",
                "        \"Reference Answer\": reference,\n",
                "        \"BLEU-4\": scores['bleu'],\n",
                "        \"ROUGE-L\": scores['rouge']\n",
                "    })\n",
                "    print(f\".\", end=\"\") # Progress indicator\n",
                "\n",
                "print(\"\\nDone!\")\n",
                "print_system_usage(\"Inference Complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Evaluation Summary ---\n",
                        "Average BLEU-4: 0.0039\n",
                        "Average ROUGE-L: 0.1023\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Question</th>\n",
                            "      <th>Generated Answer</th>\n",
                            "      <th>BLEU-4</th>\n",
                            "      <th>ROUGE-L</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Who are Zuleika's most prominent suitors?</td>\n",
                            "      <td>The text does not mention who Zuleikaâ€™s most p...</td>\n",
                            "      <td>0.010331</td>\n",
                            "      <td>0.200000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>Why does Zuleika reject the Duke?</td>\n",
                            "      <td>Please provide me with the context! I need the...</td>\n",
                            "      <td>0.009134</td>\n",
                            "      <td>0.060606</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Who is the first person Zuleika falls in love ...</td>\n",
                            "      <td>According to the text, Zuleika falls in love w...</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.117647</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>Where do Zuleika and her suitors meet?</td>\n",
                            "      <td>According to the text, Zuleika and her suitors...</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.133333</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>How does Zuleika stop the Duke's first suicide...</td>\n",
                            "      <td>Please provide me with the context! I need the...</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                            Question  \\\n",
                            "0          Who are Zuleika's most prominent suitors?   \n",
                            "1                  Why does Zuleika reject the Duke?   \n",
                            "2  Who is the first person Zuleika falls in love ...   \n",
                            "3             Where do Zuleika and her suitors meet?   \n",
                            "4  How does Zuleika stop the Duke's first suicide...   \n",
                            "\n",
                            "                                    Generated Answer    BLEU-4   ROUGE-L  \n",
                            "0  The text does not mention who Zuleikaâ€™s most p...  0.010331  0.200000  \n",
                            "1  Please provide me with the context! I need the...  0.009134  0.060606  \n",
                            "2  According to the text, Zuleika falls in love w...  0.000000  0.117647  \n",
                            "3  According to the text, Zuleika and her suitors...  0.000000  0.133333  \n",
                            "4  Please provide me with the context! I need the...  0.000000  0.000000  "
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
                        "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
                        "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
                        "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
                    ]
                }
            ],
            "source": [
                "# Results Analysis\n",
                "df_results = pd.DataFrame(results)\n",
                "\n",
                "# Calculate Averages\n",
                "avg_bleu = df_results['BLEU-4'].mean()\n",
                "avg_rouge = df_results['ROUGE-L'].mean()\n",
                "\n",
                "print(\"--- Evaluation Summary ---\")\n",
                "print(f\"Average BLEU-4: {avg_bleu:.4f}\")\n",
                "print(f\"Average ROUGE-L: {avg_rouge:.4f}\")\n",
                "\n",
                "# Display Table\n",
                "df_results[['Question', 'Generated Answer', 'BLEU-4', 'ROUGE-L']]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
