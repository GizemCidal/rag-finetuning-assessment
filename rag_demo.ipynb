{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Advanced RAG System Demo\n",
                "\n",
                "### Objectives:\n",
                "1. **System Resource Monitoring**: Track RAM/CPU usage during heavy tasks.\n",
                "2. **Pipeline Execution**: Load data, chunk, index, retrieve, and generate.\n",
                "3. **Evaluation**: Compare Generated Answers vs Reference Answers using **BLEU-4** and **ROUGE-L** metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: qdrant-client in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.16.2)\n",
                        "Requirement already satisfied: transformers in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.57.3)\n",
                        "Requirement already satisfied: sentence-transformers in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (5.2.0)\n",
                        "Requirement already satisfied: datasets in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.4.1)\n",
                        "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (2.9.1)\n",
                        "Requirement already satisfied: accelerate in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.12.0)\n",
                        "Requirement already satisfied: bitsandbytes in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.49.0)\n",
                        "Requirement already satisfied: nltk in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (3.9.2)\n",
                        "Requirement already satisfied: rouge_score in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.1.2)\n",
                        "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2.2.6)\n",
                        "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.3.3)\n",
                        "Requirement already satisfied: ipywidgets in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (8.1.8)\n",
                        "Requirement already satisfied: peft in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.18.0)\n",
                        "Requirement already satisfied: trl in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.26.1)\n",
                        "Requirement already satisfied: scipy in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (1.15.3)\n",
                        "Requirement already satisfied: wandb in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.23.1)\n",
                        "Requirement already satisfied: python-dotenv in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (1.2.1)\n",
                        "Requirement already satisfied: httpx[http2]>=0.20.0 in ./venv/lib/python3.10/site-packages (from qdrant-client->-r requirements.txt (line 1)) (0.28.1)\n",
                        "Requirement already satisfied: grpcio>=1.41.0 in ./venv/lib/python3.10/site-packages (from qdrant-client->-r requirements.txt (line 1)) (1.76.0)\n",
                        "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in ./venv/lib/python3.10/site-packages (from qdrant-client->-r requirements.txt (line 1)) (2.12.5)\n",
                        "Requirement already satisfied: portalocker<4.0,>=2.7.0 in ./venv/lib/python3.10/site-packages (from qdrant-client->-r requirements.txt (line 1)) (3.2.0)\n",
                        "Requirement already satisfied: urllib3<3,>=1.26.14 in ./venv/lib/python3.10/site-packages (from qdrant-client->-r requirements.txt (line 1)) (2.6.2)\n",
                        "Requirement already satisfied: protobuf>=3.20.0 in ./venv/lib/python3.10/site-packages (from qdrant-client->-r requirements.txt (line 1)) (6.33.2)\n",
                        "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (6.0.3)\n",
                        "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.36.0)\n",
                        "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (3.20.0)\n",
                        "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (4.67.1)\n",
                        "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (2025.11.3)\n",
                        "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (2.32.5)\n",
                        "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.22.1)\n",
                        "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (25.0)\n",
                        "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.7.0)\n",
                        "Requirement already satisfied: typing_extensions>=4.5.0 in ./venv/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 3)) (4.15.0)\n",
                        "Requirement already satisfied: scikit-learn in ./venv/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 3)) (1.7.2)\n",
                        "Requirement already satisfied: xxhash in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 4)) (3.6.0)\n",
                        "Requirement already satisfied: dill<0.4.1,>=0.3.0 in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 4)) (0.4.0)\n",
                        "Requirement already satisfied: pyarrow>=21.0.0 in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 4)) (22.0.0)\n",
                        "Requirement already satisfied: fsspec[http]<=2025.10.0,>=2023.1.0 in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 4)) (2025.10.0)\n",
                        "Requirement already satisfied: multiprocess<0.70.19 in ./venv/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 4)) (0.70.18)\n",
                        "Requirement already satisfied: networkx>=2.5.1 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (3.4.2)\n",
                        "Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (1.14.0)\n",
                        "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch->-r requirements.txt (line 5)) (3.1.6)\n",
                        "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 6)) (7.1.3)\n",
                        "Requirement already satisfied: joblib in ./venv/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 8)) (1.5.2)\n",
                        "Requirement already satisfied: click in ./venv/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 8)) (8.3.1)\n",
                        "Requirement already satisfied: six>=1.14.0 in ./venv/lib/python3.10/site-packages (from rouge_score->-r requirements.txt (line 9)) (1.17.0)\n",
                        "Requirement already satisfied: absl-py in ./venv/lib/python3.10/site-packages (from rouge_score->-r requirements.txt (line 9)) (2.3.1)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 11)) (2025.2)\n",
                        "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 11)) (2025.2)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 11)) (2.9.0.post0)\n",
                        "Requirement already satisfied: ipython>=6.1.0 in ./venv/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 12)) (8.37.0)\n",
                        "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./venv/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 12)) (3.0.16)\n",
                        "Requirement already satisfied: comm>=0.1.3 in ./venv/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 12)) (0.2.3)\n",
                        "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./venv/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 12)) (4.0.15)\n",
                        "Requirement already satisfied: traitlets>=4.3.1 in ./venv/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 12)) (5.14.3)\n",
                        "Requirement already satisfied: sentry-sdk>=2.0.0 in ./venv/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 16)) (2.47.0)\n",
                        "Requirement already satisfied: platformdirs in ./venv/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 16)) (4.5.1)\n",
                        "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./venv/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 16)) (3.1.45)\n",
                        "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./venv/lib/python3.10/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (3.13.2)\n",
                        "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (25.4.0)\n",
                        "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (5.0.1)\n",
                        "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (0.4.1)\n",
                        "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (1.22.0)\n",
                        "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (2.6.1)\n",
                        "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (1.4.0)\n",
                        "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (6.7.0)\n",
                        "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (1.8.0)\n",
                        "Requirement already satisfied: gitdb<5,>=4.0.1 in ./venv/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 16)) (4.0.12)\n",
                        "Requirement already satisfied: smmap<6,>=3.0.1 in ./venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 16)) (5.0.2)\n",
                        "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (1.0.9)\n",
                        "Requirement already satisfied: idna in ./venv/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (3.11)\n",
                        "Requirement already satisfied: certifi in ./venv/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (2025.11.12)\n",
                        "Requirement already satisfied: anyio in ./venv/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (4.12.0)\n",
                        "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.10/site-packages (from httpcore==1.*->httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (0.16.0)\n",
                        "Requirement already satisfied: h2<5,>=3 in ./venv/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (4.3.0)\n",
                        "Requirement already satisfied: hyperframe<7,>=6.1 in ./venv/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (6.1.0)\n",
                        "Requirement already satisfied: hpack<5,>=4.1 in ./venv/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client->-r requirements.txt (line 1)) (4.1.0)\n",
                        "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 2)) (1.2.0)\n",
                        "Requirement already satisfied: exceptiongroup in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (1.3.1)\n",
                        "Requirement already satisfied: matplotlib-inline in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (0.2.1)\n",
                        "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (3.0.52)\n",
                        "Requirement already satisfied: stack_data in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (0.6.3)\n",
                        "Requirement already satisfied: pygments>=2.4.0 in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (2.19.2)\n",
                        "Requirement already satisfied: pexpect>4.3 in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (4.9.0)\n",
                        "Requirement already satisfied: decorator in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (5.2.1)\n",
                        "Requirement already satisfied: jedi>=0.16 in ./venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (0.19.2)\n",
                        "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (0.8.5)\n",
                        "Requirement already satisfied: ptyprocess>=0.5 in ./venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (0.7.0)\n",
                        "Requirement already satisfied: wcwidth in ./venv/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (0.2.14)\n",
                        "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client->-r requirements.txt (line 1)) (0.7.0)\n",
                        "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client->-r requirements.txt (line 1)) (2.41.5)\n",
                        "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client->-r requirements.txt (line 1)) (0.4.2)\n",
                        "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 2)) (3.4.4)\n",
                        "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 5)) (1.3.0)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 5)) (3.0.3)\n",
                        "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 3)) (3.6.0)\n",
                        "Requirement already satisfied: executing>=1.2.0 in ./venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (2.2.1)\n",
                        "Requirement already satisfied: asttokens>=2.1.0 in ./venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (3.0.1)\n",
                        "Requirement already satisfied: pure-eval in ./venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 12)) (0.2.3)\n",
                        "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
                        "You should consider upgrading via the '/Users/gizemcidal/Desktop/rag_and_finetuning_task_vdf/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "# Setup Environment & Utils\n",
                "!pip install -r requirements.txt\n",
                "\n",
                "import sys\n",
                "import os\n",
                "import psutil\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Ensure src is in python path\n",
                "sys.path.append(os.getcwd())\n",
                "\n",
                "def print_system_usage(stage=\"\"):\n",
                "    process = psutil.Process(os.getpid())\n",
                "    mem_info = process.memory_info()\n",
                "    mem_mb = mem_info.rss / 1024 / 1024\n",
                "    print(f\"[{stage}] Memory: {mem_mb:.2f} MB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Configuration Loaded.\n",
                        "[Init] Memory: 524.97 MB\n"
                    ]
                }
            ],
            "source": [
                "# Load Configuration & Modules\n",
                "from rag.config import RAGConfig\n",
                "from rag.data_loader import DataLoader\n",
                "from rag.chunking import HierarchicalChunker\n",
                "from rag.vector_db import VectorDBHandler\n",
                "from rag.retriever import HierarchicalRetriever\n",
                "from rag.generator import RAGGenerator\n",
                "from rag.evaluator import Evaluator\n",
                "\n",
                "config = RAGConfig()\n",
                "print(\"Configuration Loaded.\")\n",
                "print_system_usage(\"Init\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Logging in with token from .env...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
                    ]
                }
            ],
            "source": [
                "# Authenticate with Hugging Face (Required for Gemma Model)\n",
                "from huggingface_hub import login\n",
                "\n",
                "# Load existing .env file\n",
                "load_dotenv()\n",
                "hf_token = os.getenv(\"HF_TOKEN\")\n",
                "\n",
                "if hf_token and hf_token != \"your_huggingface_token_here\":\n",
                "    print(\"Logging in with token from .env...\")\n",
                "    login(token=hf_token)\n",
                "else:\n",
                "    print(\"Please Paste Token manually or update .env file.\")\n",
                "    print(\"Get token: https://huggingface.co/settings/tokens\")\n",
                "    login()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`trust_remote_code` is not supported anymore.\n",
                        "Please check that the Hugging Face dataset 'narrativeqa' isn't based on a loading script and remove `trust_remote_code`.\n",
                        "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Book already exists at /Users/gizemcidal/Desktop/rag_and_finetuning_task_vdf/data/zuleika_dobson.txt\n",
                        "Book loaded. Length: 467598 chars\n",
                        "Loading NarrativeQA test split for ID 1845...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e7fd8ab57e0d42f99938f92ff021c8cb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Resolving data files:   0%|          | 0/24 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1864d055bd694bff9a157bf855a9ffc5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Resolving data files:   0%|          | 0/24 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 40 QA pairs for Book ID 1845.\n",
                        "Loaded 40 QA pairs for testing.\n",
                        "[Data Loading] Memory: 559.77 MB\n"
                    ]
                }
            ],
            "source": [
                "# Data Loading\n",
                "loader = DataLoader(config)\n",
                "\n",
                "# Download Book\n",
                "book_text = loader.download_book()\n",
                "print(f\"Book loaded. Length: {len(book_text)} chars\")\n",
                "\n",
                "# Load QA Pairs\n",
                "qa_pairs = loader.load_qa_pairs()\n",
                "print(f\"Loaded {len(qa_pairs)} QA pairs for testing.\")\n",
                "print_system_usage(\"Data Loading\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Created 346 parent chunks and 30866 child chunks.\n",
                        "[Chunking] Memory: 574.44 MB\n"
                    ]
                }
            ],
            "source": [
                "# Hierarchical Chunking\n",
                "chunker = HierarchicalChunker(\n",
                "    parent_chunk_size=config.PARENT_CHUNK_SIZE,\n",
                "    child_chunk_size=config.CHILD_CHUNK_SIZE,\n",
                "    overlap=config.CHUNK_OVERLAP\n",
                ")\n",
                "\n",
                "chunks = chunker.chunk_data(book_text)\n",
                "print(f\"Created {len(chunks['parents'])} parent chunks and {len(chunks['children'])} child chunks.\")\n",
                "\n",
                "parents = chunks['parents']\n",
                "children = chunks['children']\n",
                "print_system_usage(\"Chunking\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Initializing Qdrant at /Users/gizemcidal/Desktop/rag_and_finetuning_task_vdf/data/qdrant_db\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/gizemcidal/Desktop/rag_and_finetuning_task_vdf/rag/vector_db.py:13: UserWarning: Local mode is not recommended for collections with more than 20,000 points. Collection <dracula_chunks> contains 518909 points. Consider using Qdrant in Docker or Qdrant Cloud for better performance with large datasets.\n",
                        "  self.client = QdrantClient(path=self.config.QDRANT_PATH)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collection dracula_chunks already exists.\n",
                        "Indexing chunks... (this creates embeddings using CPU/GPU)\n",
                        "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
                        "Generating embeddings for 30866 chunks...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6bca3504d49645e49b46fd9ab6e16ff8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Batches:   0%|          | 0/965 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/gizemcidal/Desktop/rag_and_finetuning_task_vdf/rag/vector_db.py:52: UserWarning: Local mode is not recommended for collections with more than 20,000 points. Current collection contains 519009 points. Consider using Qdrant in Docker or Qdrant Cloud for better performance with large datasets.\n",
                        "  self.client.upsert(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Upserted 30866 points.\n",
                        "[Indexing] Memory: 8574.31 MB\n"
                    ]
                }
            ],
            "source": [
                "# Indexing in Qdrant (Local Disk Mode)\n",
                "# CRITICAL: Force cleanup of previous instances to release file locks\n",
                "import gc\n",
                "try:\n",
                "    if 'vdb' in locals():\n",
                "        print(\"Cleaning up previous DB instance...\")\n",
                "        if hasattr(vdb, 'close'):\n",
                "            vdb.close()\n",
                "        del vdb\n",
                "        gc.collect() # Force garbage collection to release file handles\n",
                "except Exception as e:\n",
                "    print(f\"Cleanup warning: {e}\")\n",
                "\n",
                "vdb = VectorDBHandler(config)\n",
                "vdb.create_collection()\n",
                "\n",
                "print(\"Indexing chunks... (this creates embeddings using CPU/GPU)\")\n",
                "vdb.index_chunks(chunks)\n",
                "print_system_usage(\"Indexing\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
                        "Loading Reranker model: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f20700f22fd84bef9462b0f9efa8f53e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6f4eb88a0e2d4996b17eb397d9d2677a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "47a9b0e0fc6044e393caba9a10965d30",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer_config.json: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "62de2f1c612846658866ab809a208b5b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "vocab.txt: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4fb99782b65146128f816c2cecb11b74",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer.json: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3d9bfb66630b4085b0ca52db4e6aadcd",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "737d19347da7403e8653dffc75efd59a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "README.md: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading LLM: google/gemma-3-1b-it\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`torch_dtype` is deprecated! Use `dtype` instead!\n",
                        "Device set to use mps\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "RAG Components Ready.\n",
                        "[Model Load] Memory: 1234.86 MB\n"
                    ]
                }
            ],
            "source": [
                "# Initialize Components\n",
                "retriever = HierarchicalRetriever(config, vdb, parents)\n",
                "generator = RAGGenerator(config)\n",
                "evaluator = Evaluator()\n",
                "print(\"RAG Components Ready.\")\n",
                "print_system_usage(\"Model Load\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Running RAG on 5 queries...\n",
                        ".....\n",
                        "Done!\n",
                        "[Inference Complete] Memory: 3512.67 MB\n"
                    ]
                }
            ],
            "source": [
                "# Run RAG Loop & Evaluation\n",
                "import pandas as pd\n",
                "\n",
                "# Run on a subset or all pairs\n",
                "test_pairs = qa_pairs[:5] # Testing on first 5 pairs for demo speed\n",
                "results = []\n",
                "\n",
                "print(f\"Running RAG on {len(test_pairs)} queries...\")\n",
                "\n",
                "for i, qa in enumerate(test_pairs):\n",
                "    question = qa['question']\n",
                "    reference = qa['answer1']\n",
                "    \n",
                "    # 1. Retrieve\n",
                "    context = retriever.retrieve_context(question, top_k=config.TOP_K)\n",
                "    \n",
                "    # 2. Generate\n",
                "    generated_answer = generator.generate_answer(question, context)\n",
                "    \n",
                "    # 3. Evaluate\n",
                "    scores = evaluator.evaluate(generated_answer, reference)\n",
                "    \n",
                "    results.append({\n",
                "        \"Question\": question,\n",
                "        \"Generated Answer\": generated_answer,\n",
                "        \"Reference Answer\": reference,\n",
                "        \"BLEU-4\": scores['bleu'],\n",
                "        \"ROUGE-L\": scores['rouge']\n",
                "    })\n",
                "    print(f\".\", end=\"\") # Progress indicator\n",
                "\n",
                "print(\"\\nDone!\")\n",
                "print_system_usage(\"Inference Complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Evaluation Summary ---\n",
                        "Average BLEU-4: 0.0039\n",
                        "Average ROUGE-L: 0.1023\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Question</th>\n",
                            "      <th>Generated Answer</th>\n",
                            "      <th>BLEU-4</th>\n",
                            "      <th>ROUGE-L</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Who are Zuleika's most prominent suitors?</td>\n",
                            "      <td>The text does not mention who Zuleika’s most p...</td>\n",
                            "      <td>0.010331</td>\n",
                            "      <td>0.200000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>Why does Zuleika reject the Duke?</td>\n",
                            "      <td>Please provide me with the context! I need the...</td>\n",
                            "      <td>0.009134</td>\n",
                            "      <td>0.060606</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Who is the first person Zuleika falls in love ...</td>\n",
                            "      <td>According to the text, Zuleika falls in love w...</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.117647</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>Where do Zuleika and her suitors meet?</td>\n",
                            "      <td>According to the text, Zuleika and her suitors...</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.133333</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>How does Zuleika stop the Duke's first suicide...</td>\n",
                            "      <td>Please provide me with the context! I need the...</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                            Question  \\\n",
                            "0          Who are Zuleika's most prominent suitors?   \n",
                            "1                  Why does Zuleika reject the Duke?   \n",
                            "2  Who is the first person Zuleika falls in love ...   \n",
                            "3             Where do Zuleika and her suitors meet?   \n",
                            "4  How does Zuleika stop the Duke's first suicide...   \n",
                            "\n",
                            "                                    Generated Answer    BLEU-4   ROUGE-L  \n",
                            "0  The text does not mention who Zuleika’s most p...  0.010331  0.200000  \n",
                            "1  Please provide me with the context! I need the...  0.009134  0.060606  \n",
                            "2  According to the text, Zuleika falls in love w...  0.000000  0.117647  \n",
                            "3  According to the text, Zuleika and her suitors...  0.000000  0.133333  \n",
                            "4  Please provide me with the context! I need the...  0.000000  0.000000  "
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
                        "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
                        "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
                        "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
                    ]
                }
            ],
            "source": [
                "# Results Analysis\n",
                "df_results = pd.DataFrame(results)\n",
                "\n",
                "# Calculate Averages\n",
                "avg_bleu = df_results['BLEU-4'].mean()\n",
                "avg_rouge = df_results['ROUGE-L'].mean()\n",
                "\n",
                "print(\"--- Evaluation Summary ---\")\n",
                "print(f\"Average BLEU-4: {avg_bleu:.4f}\")\n",
                "print(f\"Average ROUGE-L: {avg_rouge:.4f}\")\n",
                "\n",
                "# Display Table\n",
                "df_results[['Question', 'Generated Answer', 'BLEU-4', 'ROUGE-L']]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
